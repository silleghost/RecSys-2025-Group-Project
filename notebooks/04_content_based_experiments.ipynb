{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea32e56c",
   "metadata": {},
   "source": [
    "# 04 — Content-Based Recommender (Experiments)\n",
    "\n",
    "This notebook benchmarks several content-based recommenders for Steam games on a sampled user set. We use BM25-weighted metadata (tags, categories, developers), dense features (price, owners buckets), optional SVD, and multiple models:\n",
    "\n",
    "- Popularity baseline.\n",
    "- Content + popularity hybrids (alpha blend).\n",
    "- Feature-kNN (precomputed neighbors on content features).\n",
    "- LightFM hybrid (item features + implicit interactions) with a small sweep.\n",
    "- Logistic regression scorer (pointwise, content+pop features with negative sampling).\n",
    "\n",
    "Metrics: HitRate, Recall, NDCG at K (shared evaluator from `src.evaluation`). Seen items are excluded in recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f404573",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- Sample a subset of users for speed (adjust `SAMPLE_USERS`).\n",
    "- Build BM25 + dense features; optional SVD.\n",
    "- Run sweeps on alphas, kNN neighbors, LightFM (small), and logistic scorer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c3eee5-9360-482e-8b9f-0cbb6ae1d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/home/alyx/Documents/RS/Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8e5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src import config\n",
    "from src.evaluation import build_ground_truth, evaluate_model\n",
    "from src.models.popularity import PopularityRecommender\n",
    "from src.models.content_based import ContentHybridRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b39912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment params (tuned for sampled runs)\n",
    "SAMPLE_USERS = 2000\n",
    "MIN_INTERACTIONS = 10\n",
    "ALPHAS = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "KNN_NEIGHBORS = [50, 100, 150]\n",
    "VOCAB_TAGS = 4000\n",
    "VOCAB_CATEGORIES = 2000\n",
    "VOCAB_DEVELOPERS = 1000\n",
    "USE_SVD = True\n",
    "SVD_COMPONENTS = [128, 256]\n",
    "BM25_K1 = 1.6\n",
    "BM25_B = 0.75\n",
    "LIGHTFM_FACTORS = [32, 64]\n",
    "LIGHTFM_EPOCHS = [5]\n",
    "LIGHTFM_LOSSES = [\"warp\"]\n",
    "LOGREG_NEG_PER_POS = 2\n",
    "LOGREG_MAX_USERS = 2000\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486e22b",
   "metadata": {},
   "source": [
    "## Load processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shapes: (9117646, 2) (44021, 2) (89618, 4239) (89618, 47)\n"
     ]
    }
   ],
   "source": [
    "USER_COL = config.USER_COL\n",
    "ITEM_COL = config.ITEM_COL\n",
    "\n",
    "train_df = pd.read_parquet(config.PROCESSED_DATA_DIR / \"train_interactions.parquet\")\n",
    "test_df = pd.read_parquet(config.PROCESSED_DATA_DIR / \"test_interactions.parquet\")\n",
    "item_features = pd.read_parquet(config.PROCESSED_DATA_DIR / \"item_features.parquet\").fillna(0)\n",
    "games_meta = pd.read_parquet(config.PROCESSED_DATA_DIR / \"games_metadata.parquet\")\n",
    "\n",
    "print(\"Raw shapes:\", train_df.shape, test_df.shape, item_features.shape, games_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084d0c6",
   "metadata": {},
   "source": [
    "## Sample users (for speed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876c7052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 2000 users -> train (454394, 2), test (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "user_counts = train_df[USER_COL].value_counts()\n",
    "eligible_users = user_counts[user_counts >= MIN_INTERACTIONS].index\n",
    "\n",
    "if SAMPLE_USERS:\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    sample_size = min(SAMPLE_USERS, len(eligible_users))\n",
    "    sampled_users = rng.choice(eligible_users, size=sample_size, replace=False)\n",
    "    train_df = train_df[train_df[USER_COL].isin(sampled_users)].copy()\n",
    "    test_df = test_df[test_df[USER_COL].isin(sampled_users)].copy()\n",
    "    print(f\"Sampled {sample_size} users -> train {train_df.shape}, test {test_df.shape}\")\n",
    "else:\n",
    "    train_df = train_df[train_df[USER_COL].isin(eligible_users)].copy()\n",
    "    test_df = test_df[test_df[USER_COL].isin(eligible_users)].copy()\n",
    "    print(f\"Using all eligible users -> train {train_df.shape}, test {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd09924",
   "metadata": {},
   "source": [
    "## Feature helpers (BM25 + dense + optional SVD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cd9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_block(series: pd.Series, max_features: int, k1: float = BM25_K1, b: float = BM25_B):\n",
    "    texts = series.fillna(\"\").astype(str).tolist()\n",
    "    vec = CountVectorizer(max_features=max_features)\n",
    "    X = vec.fit_transform(texts)\n",
    "    tf = X\n",
    "    dl = np.asarray(tf.sum(axis=1)).ravel()\n",
    "    avg_dl = dl.mean() + 1e-8\n",
    "    idf = np.log((tf.shape[0] - tf.astype(bool).sum(axis=0) + 0.5) / (tf.astype(bool).sum(axis=0) + 0.5)) + 1\n",
    "    idf = np.asarray(idf).ravel()\n",
    "    denom = tf + k1 * (1 - b + b * (dl / avg_dl))[:, None]\n",
    "    numer = tf.multiply(k1 + 1)\n",
    "    bm25 = numer.multiply(1 / denom)\n",
    "    bm25 = bm25.multiply(idf)\n",
    "    return bm25.tocsr()\n",
    "\n",
    "def build_feature_matrix(base_feats: pd.DataFrame, meta: pd.DataFrame, use_svd: bool, svd_components: Optional[int]):\n",
    "    items = base_feats[ITEM_COL].astype(int).tolist()\n",
    "    meta_aligned = meta.set_index(ITEM_COL).reindex(base_feats[ITEM_COL]).reset_index()\n",
    "\n",
    "    blocks = []\n",
    "    # Base dense\n",
    "    blocks.append(csr_matrix(base_feats.drop(columns=[ITEM_COL]).to_numpy(dtype=np.float32)))\n",
    "\n",
    "    # Price/owners buckets\n",
    "    price_col = config.PRICE_COL\n",
    "    if price_col in meta_aligned.columns:\n",
    "        prices = pd.to_numeric(meta_aligned[price_col], errors=\"coerce\").fillna(0)\n",
    "        bins = [0, 1, 5, 10, 20, 50, 100, np.inf]\n",
    "        labels = [f\"price_bin_{i}\" for i in range(len(bins)-1)]\n",
    "        price_bins = pd.get_dummies(pd.cut(prices, bins=bins, labels=labels, include_lowest=True))\n",
    "    else:\n",
    "        price_bins = pd.DataFrame(index=meta_aligned.index)\n",
    "\n",
    "    if \"estimated_owners\" in meta_aligned.columns:\n",
    "        owners_raw = meta_aligned[\"estimated_owners\"].fillna(\"\")\n",
    "        def parse_owner(val):\n",
    "            if isinstance(val, str) and \"-\" in val:\n",
    "                try:\n",
    "                    low = val.split(\"-\")[0].replace(\",\", \"\").strip()\n",
    "                    return float(low)\n",
    "                except Exception:\n",
    "                    return np.nan\n",
    "            try:\n",
    "                return float(val)\n",
    "            except Exception:\n",
    "                return np.nan\n",
    "        owners_num = owners_raw.apply(parse_owner)\n",
    "        bins = [0, 1e3, 1e4, 1e5, 1e6, 1e7, np.inf]\n",
    "        labels = [f\"owners_bin_{i}\" for i in range(len(bins)-1)]\n",
    "        owner_bins = pd.get_dummies(pd.cut(owners_num, bins=bins, labels=labels, include_lowest=True))\n",
    "    else:\n",
    "        owner_bins = pd.DataFrame(index=meta_aligned.index)\n",
    "\n",
    "    extra_dense = pd.concat([price_bins, owner_bins], axis=1).fillna(0)\n",
    "    blocks.append(csr_matrix(extra_dense.to_numpy(dtype=np.float32)))\n",
    "\n",
    "    # BM25 text blocks\n",
    "    if \"categories\" in meta_aligned.columns:\n",
    "        blocks.append(bm25_block(meta_aligned[\"categories\"], max_features=VOCAB_CATEGORIES))\n",
    "    if \"developers\" in meta_aligned.columns:\n",
    "        blocks.append(bm25_block(meta_aligned[\"developers\"], max_features=VOCAB_DEVELOPERS))\n",
    "    if \"tags\" in meta_aligned.columns:\n",
    "        blocks.append(bm25_block(meta_aligned[\"tags\"], max_features=VOCAB_TAGS))\n",
    "\n",
    "    matrix = hstack(blocks).tocsr()\n",
    "\n",
    "    if use_svd and svd_components:\n",
    "        svd = TruncatedSVD(n_components=svd_components, random_state=RANDOM_STATE)\n",
    "        matrix = svd.fit_transform(matrix)\n",
    "        matrix = normalize(matrix)\n",
    "        matrix = csr_matrix(matrix)\n",
    "\n",
    "    matrix = normalize(matrix, norm=\"l2\", axis=1)\n",
    "    item_to_idx = {iid: i for i, iid in enumerate(items)}\n",
    "    return items, item_to_idx, matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457a157",
   "metadata": {},
   "source": [
    "## Prepare features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd8c2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_in_split = set(train_df[ITEM_COL]) | set(test_df[ITEM_COL])\n",
    "base_feats = item_features[item_features[ITEM_COL].isin(items_in_split)].copy().reset_index(drop=True)\n",
    "meta_filtered = games_meta[games_meta[ITEM_COL].isin(items_in_split)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27724501",
   "metadata": {},
   "source": [
    "## Evaluation setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c72108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users for eval: 2000\n"
     ]
    }
   ],
   "source": [
    "ground_truth = build_ground_truth(test_df, user_col=USER_COL, item_col=ITEM_COL)\n",
    "users_eval = list(ground_truth.keys())\n",
    "known_items_map = train_df.groupby(USER_COL)[ITEM_COL].apply(list).to_dict()\n",
    "print(f\"Users for eval: {len(users_eval)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ea3f3",
   "metadata": {},
   "source": [
    "## Feature-kNN helper (precomputed neighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4e5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecomputedFeatureKNN:\n",
    "    def __init__(self, item_matrix: csr_matrix, item_ids: List[int], item_to_idx: Dict[int, int], max_neighbors: int = 200):\n",
    "        self.item_matrix = item_matrix\n",
    "        self.item_ids = item_ids\n",
    "        self.item_to_idx = item_to_idx\n",
    "        self.max_neighbors = min(max_neighbors, item_matrix.shape[0]-1)\n",
    "        knn = NearestNeighbors(metric=\"cosine\", n_neighbors=self.max_neighbors)\n",
    "        knn.fit(item_matrix)\n",
    "        distances, neighbors = knn.kneighbors(item_matrix, n_neighbors=self.max_neighbors)\n",
    "        self.neighbors = neighbors\n",
    "        self.sims = 1 - distances\n",
    "        self.default_n_neighbors = self.max_neighbors\n",
    "\n",
    "    def recommend(self, user_id: int, known_items: List[int], k: int) -> List[int]:\n",
    "        if not known_items:\n",
    "            return []\n",
    "        known_idx = [self.item_to_idx[i] for i in known_items if i in self.item_to_idx]\n",
    "        if not known_idx:\n",
    "            return []\n",
    "        scores = np.zeros(self.item_matrix.shape[0], dtype=np.float32)\n",
    "        n_use = self.default_n_neighbors\n",
    "        for idx in known_idx:\n",
    "            neigh = self.neighbors[idx, :n_use]\n",
    "            sim = self.sims[idx, :n_use]\n",
    "            scores[neigh] += sim\n",
    "        for idx in known_idx:\n",
    "            scores[idx] = -np.inf\n",
    "        top_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_idx = top_idx[np.argsort(scores[top_idx])[::-1]]\n",
    "        return [self.item_ids[i] for i in top_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2aa0b",
   "metadata": {},
   "source": [
    "## Sweeps: hybrids, kNN, SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "396c8153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD settings:   0%|                                                                          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature store (SVD=128) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Alphas (SVD=128):   0%|                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Alphas (SVD=128):  10%|██████                                                       | 1/10 [00:08<01:12,  8.02s/it]\u001b[A\n",
      "Alphas (SVD=128):  20%|████████████▏                                                | 2/10 [00:15<01:03,  7.95s/it]\u001b[A\n",
      "Alphas (SVD=128):  30%|██████████████████▎                                          | 3/10 [00:22<00:52,  7.49s/it]\u001b[A\n",
      "Alphas (SVD=128):  40%|████████████████████████▍                                    | 4/10 [00:29<00:44,  7.34s/it]\u001b[A\n",
      "Alphas (SVD=128):  50%|██████████████████████████████▌                              | 5/10 [00:37<00:36,  7.35s/it]\u001b[A\n",
      "Alphas (SVD=128):  60%|████████████████████████████████████▌                        | 6/10 [00:44<00:29,  7.42s/it]\u001b[A\n",
      "Alphas (SVD=128):  70%|██████████████████████████████████████████▋                  | 7/10 [00:53<00:23,  7.73s/it]\u001b[A\n",
      "Alphas (SVD=128):  80%|████████████████████████████████████████████████▊            | 8/10 [01:00<00:15,  7.64s/it]\u001b[A\n",
      "Alphas (SVD=128):  90%|██████████████████████████████████████████████████████▉      | 9/10 [01:07<00:07,  7.41s/it]\u001b[A\n",
      "Alphas (SVD=128): 100%|████████████████████████████████████████████████████████████| 10/10 [01:15<00:00,  7.52s/it]\u001b[A\n",
      "\n",
      "kNN (SVD=128):   0%|                                                                         | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "kNN (SVD=128):  33%|█████████████████████▋                                           | 1/3 [00:02<00:05,  2.59s/it]\u001b[A\n",
      "kNN (SVD=128):  67%|███████████████████████████████████████████▎                     | 2/3 [00:05<00:02,  2.54s/it]\u001b[A\n",
      "kNN (SVD=128): 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.55s/it]\u001b[A\n",
      "SVD settings:  50%|████████████████████████████████▌                                | 1/2 [02:58<02:58, 178.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature store (SVD=256) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Alphas (SVD=256):   0%|                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Alphas (SVD=256):  10%|██████                                                       | 1/10 [00:12<01:50, 12.33s/it]\u001b[A\n",
      "Alphas (SVD=256):  20%|████████████▏                                                | 2/10 [00:24<01:38, 12.30s/it]\u001b[A\n",
      "Alphas (SVD=256):  30%|██████████████████▎                                          | 3/10 [00:36<01:26, 12.32s/it]\u001b[A\n",
      "Alphas (SVD=256):  40%|████████████████████████▍                                    | 4/10 [00:49<01:13, 12.31s/it]\u001b[A\n",
      "Alphas (SVD=256):  50%|██████████████████████████████▌                              | 5/10 [01:01<01:01, 12.32s/it]\u001b[A\n",
      "Alphas (SVD=256):  60%|████████████████████████████████████▌                        | 6/10 [01:14<00:49, 12.35s/it]\u001b[A\n",
      "Alphas (SVD=256):  70%|██████████████████████████████████████████▋                  | 7/10 [01:26<00:37, 12.34s/it]\u001b[A\n",
      "Alphas (SVD=256):  80%|████████████████████████████████████████████████▊            | 8/10 [01:39<00:25, 12.55s/it]\u001b[A\n",
      "Alphas (SVD=256):  90%|██████████████████████████████████████████████████████▉      | 9/10 [01:53<00:12, 12.91s/it]\u001b[A\n",
      "Alphas (SVD=256): 100%|████████████████████████████████████████████████████████████| 10/10 [02:07<00:00, 12.76s/it]\u001b[A\n",
      "\n",
      "kNN (SVD=256):   0%|                                                                         | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "kNN (SVD=256):  33%|█████████████████████▋                                           | 1/3 [00:02<00:05,  2.68s/it]\u001b[A\n",
      "kNN (SVD=256):  67%|███████████████████████████████████████████▎                     | 2/3 [00:05<00:02,  2.63s/it]\u001b[A\n",
      "kNN (SVD=256): 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.64s/it]\u001b[A\n",
      "SVD settings: 100%|█████████████████████████████████████████████████████████████████| 2/2 [08:39<00:00, 259.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    k  hit_rate  recall      ndcg              model  svd\n",
       " 0   5    0.0835  0.0835  0.058795         popularity  128\n",
       " 1  10    0.1190  0.1190  0.070056         popularity  128\n",
       " 2  20    0.1850  0.1850  0.086637         popularity  128\n",
       " 0   5    0.0810  0.0810  0.058294  hybrid_alpha_0.05  128\n",
       " 1  10    0.1230  0.1230  0.071708  hybrid_alpha_0.05  128,\n",
       "                       hit_rate                      ndcg                      \\\n",
       " k                           5       10      20        5         10        20   \n",
       " model             svd                                                          \n",
       " feature_knn_100   128   0.0215  0.0345  0.0600  0.014138  0.018388  0.024826   \n",
       "                   256   0.0295  0.0495  0.0740  0.018658  0.025072  0.031180   \n",
       " feature_knn_150   128   0.0215  0.0355  0.0575  0.013438  0.018026  0.023563   \n",
       "                   256   0.0300  0.0440  0.0710  0.019683  0.024143  0.030853   \n",
       " feature_knn_50    128   0.0230  0.0405  0.0625  0.015539  0.021267  0.026717   \n",
       "                   256   0.0290  0.0490  0.0750  0.017202  0.023636  0.030088   \n",
       " hybrid_alpha_0.05 128   0.0810  0.1230  0.1855  0.058294  0.071708  0.087466   \n",
       "                   256   0.0810  0.1225  0.1860  0.058294  0.071564  0.087580   \n",
       " hybrid_alpha_0.1  128   0.0810  0.1265  0.1885  0.058366  0.072861  0.088431   \n",
       "                   256   0.0820  0.1260  0.1880  0.058719  0.072769  0.088379   \n",
       " hybrid_alpha_0.15 128   0.0825  0.1265  0.1890  0.059179  0.073286  0.089051   \n",
       "                   256   0.0835  0.1255  0.1900  0.059816  0.073298  0.089555   \n",
       " hybrid_alpha_0.2  128   0.0845  0.1240  0.1925  0.060409  0.073264  0.090513   \n",
       "                   256   0.0855  0.1240  0.1905  0.060752  0.073306  0.090116   \n",
       " hybrid_alpha_0.25 128   0.0850  0.1265  0.1895  0.060905  0.074443  0.090315   \n",
       "                   256   0.0860  0.1285  0.1880  0.061389  0.075170  0.090167   \n",
       " hybrid_alpha_0.3  128   0.0870  0.1295  0.1890  0.062211  0.075943  0.090932   \n",
       "                   256   0.0885  0.1310  0.1870  0.062581  0.076263  0.090380   \n",
       " hybrid_alpha_0.35 128   0.0865  0.1320  0.1885  0.061942  0.076606  0.090867   \n",
       "                   256   0.0875  0.1345  0.1870  0.062347  0.077498  0.090709   \n",
       " hybrid_alpha_0.4  128   0.0870  0.1340  0.1865  0.061935  0.077124  0.090450   \n",
       "                   256   0.0860  0.1355  0.1875  0.061811  0.077879  0.091003   \n",
       " hybrid_alpha_0.45 128   0.0870  0.1335  0.1875  0.062073  0.077190  0.090868   \n",
       "                   256   0.0870  0.1370  0.1840  0.061839  0.077934  0.089817   \n",
       " hybrid_alpha_0.5  128   0.0855  0.1340  0.1855  0.061111  0.076816  0.089875   \n",
       "                   256   0.0865  0.1355  0.1850  0.061262  0.077046  0.089630   \n",
       " popularity        128   0.0835  0.1190  0.1850  0.058795  0.070056  0.086637   \n",
       "                   256   0.0835  0.1190  0.1850  0.058795  0.070056  0.086637   \n",
       " \n",
       "                        recall                  \n",
       " k                          5       10      20  \n",
       " model             svd                          \n",
       " feature_knn_100   128  0.0215  0.0345  0.0600  \n",
       "                   256  0.0295  0.0495  0.0740  \n",
       " feature_knn_150   128  0.0215  0.0355  0.0575  \n",
       "                   256  0.0300  0.0440  0.0710  \n",
       " feature_knn_50    128  0.0230  0.0405  0.0625  \n",
       "                   256  0.0290  0.0490  0.0750  \n",
       " hybrid_alpha_0.05 128  0.0810  0.1230  0.1855  \n",
       "                   256  0.0810  0.1225  0.1860  \n",
       " hybrid_alpha_0.1  128  0.0810  0.1265  0.1885  \n",
       "                   256  0.0820  0.1260  0.1880  \n",
       " hybrid_alpha_0.15 128  0.0825  0.1265  0.1890  \n",
       "                   256  0.0835  0.1255  0.1900  \n",
       " hybrid_alpha_0.2  128  0.0845  0.1240  0.1925  \n",
       "                   256  0.0855  0.1240  0.1905  \n",
       " hybrid_alpha_0.25 128  0.0850  0.1265  0.1895  \n",
       "                   256  0.0860  0.1285  0.1880  \n",
       " hybrid_alpha_0.3  128  0.0870  0.1295  0.1890  \n",
       "                   256  0.0885  0.1310  0.1870  \n",
       " hybrid_alpha_0.35 128  0.0865  0.1320  0.1885  \n",
       "                   256  0.0875  0.1345  0.1870  \n",
       " hybrid_alpha_0.4  128  0.0870  0.1340  0.1865  \n",
       "                   256  0.0860  0.1355  0.1875  \n",
       " hybrid_alpha_0.45 128  0.0870  0.1335  0.1875  \n",
       "                   256  0.0870  0.1370  0.1840  \n",
       " hybrid_alpha_0.5  128  0.0855  0.1340  0.1855  \n",
       "                   256  0.0865  0.1355  0.1850  \n",
       " popularity        128  0.0835  0.1190  0.1850  \n",
       "                   256  0.0835  0.1190  0.1850  )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = []\n",
    "svd_grid = SVD_COMPONENTS if USE_SVD else [None]\n",
    "\n",
    "for svd_comp in tqdm(svd_grid, desc=\"SVD settings\"):\n",
    "    print(f\"=== Feature store (SVD={svd_comp}) ===\")\n",
    "    item_ids, item_to_idx, item_matrix = build_feature_matrix(\n",
    "        base_feats=base_feats,\n",
    "        meta=meta_filtered,\n",
    "        use_svd=USE_SVD,\n",
    "        svd_components=svd_comp,\n",
    "    )\n",
    "    pop_counts = train_df[ITEM_COL].value_counts()\n",
    "    pop_ranking = pop_counts.index.tolist()\n",
    "    pop_scores = np.zeros(len(item_ids), dtype=np.float32)\n",
    "    max_pop = pop_counts.max()\n",
    "    for iid, count in pop_counts.items():\n",
    "        idx = item_to_idx.get(iid)\n",
    "        if idx is not None:\n",
    "            pop_scores[idx] = count / max_pop\n",
    "\n",
    "    pop_model = PopularityRecommender(item_col=ITEM_COL)\n",
    "    pop_model.fit(train_df)\n",
    "    metrics_pop = evaluate_model(pop_model, ground_truth, users_eval, ks=[5, 10, 20], known_items=known_items_map)\n",
    "    metrics_pop[\"model\"] = \"popularity\"\n",
    "    metrics_pop[\"svd\"] = svd_comp\n",
    "    all_results.append(metrics_pop)\n",
    "\n",
    "    for alpha in tqdm(ALPHAS, desc=f\"Alphas (SVD={svd_comp})\"):\n",
    "        model = ContentHybridRecommender(\n",
    "            item_ids=item_ids,\n",
    "            item_to_idx=item_to_idx,\n",
    "            item_matrix=item_matrix,\n",
    "            pop_scores=pop_scores,\n",
    "            pop_ranking=pop_ranking,\n",
    "            user_col=USER_COL,\n",
    "            item_col=ITEM_COL,\n",
    "            alpha=alpha,\n",
    "        )\n",
    "        model.fit(train_df)\n",
    "        metrics = evaluate_model(model, ground_truth, users_eval, ks=[5, 10, 20], known_items=known_items_map)\n",
    "        metrics[\"model\"] = f\"hybrid_alpha_{alpha}\"\n",
    "        metrics[\"svd\"] = svd_comp\n",
    "        all_results.append(metrics)\n",
    "\n",
    "    max_k = max(KNN_NEIGHBORS)\n",
    "    knn_cache = PrecomputedFeatureKNN(item_matrix=item_matrix, item_ids=item_ids, item_to_idx=item_to_idx, max_neighbors=max_k)\n",
    "    for n_nb in tqdm(KNN_NEIGHBORS, desc=f\"kNN (SVD={svd_comp})\"):\n",
    "        knn_cache.default_n_neighbors = min(n_nb, knn_cache.max_neighbors)\n",
    "        metrics_knn = evaluate_model(knn_cache, ground_truth, users_eval, ks=[5, 10, 20], known_items=known_items_map)\n",
    "        metrics_knn[\"model\"] = f\"feature_knn_{n_nb}\"\n",
    "        metrics_knn[\"svd\"] = svd_comp\n",
    "        all_results.append(metrics_knn)\n",
    "\n",
    "all_results_df = pd.concat(all_results)\n",
    "all_results_pivot = all_results_df.pivot_table(index=[\"model\", \"svd\"], columns=\"k\", values=[\"hit_rate\", \"recall\", \"ndcg\"])\n",
    "all_results_df.head(), all_results_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d3422",
   "metadata": {},
   "source": [
    "## LightFM sweep (small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca367c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightFM loss=warp, factors=32, epochs=5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>model</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>lightfm_warp_f32_e5</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>lightfm_warp_f32_e5</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>lightfm_warp_f32_e5</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  hit_rate  recall      ndcg                model  svd\n",
       "0   5    0.0075  0.0075  0.004270  lightfm_warp_f32_e5  128\n",
       "1  10    0.0140  0.0140  0.006338  lightfm_warp_f32_e5  128\n",
       "2  20    0.0245  0.0245  0.008954  lightfm_warp_f32_e5  128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightFM loss=warp, factors=64, epochs=5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>model</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>lightfm_warp_f64_e5</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>lightfm_warp_f64_e5</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>lightfm_warp_f64_e5</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  hit_rate  recall      ndcg                model  svd\n",
       "0   5    0.0055  0.0055  0.003290  lightfm_warp_f64_e5  128\n",
       "1  10    0.0115  0.0115  0.005138  lightfm_warp_f64_e5  128\n",
       "2  20    0.0210  0.0210  0.007551  lightfm_warp_f64_e5  128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    from lightfm import LightFM\n",
    "    from lightfm.data import Dataset as LFMDataset\n",
    "\n",
    "    lfm_ds = LFMDataset()\n",
    "    lfm_ds.fit(users=train_df[USER_COL].unique(), items=train_df[ITEM_COL].unique())\n",
    "    interactions, _ = lfm_ds.build_interactions(train_df[[USER_COL, ITEM_COL]].itertuples(index=False, name=None))\n",
    "\n",
    "    item_ids_lfm, item_to_idx_lfm, item_matrix_lfm = build_feature_matrix(\n",
    "        base_feats=base_feats,\n",
    "        meta=meta_filtered,\n",
    "        use_svd=USE_SVD,\n",
    "        svd_components=SVD_COMPONENTS[0] if USE_SVD else None,\n",
    "    )\n",
    "    lfm_item_features = csr_matrix(item_matrix_lfm)\n",
    "\n",
    "    user_id_map, user_feature_map, item_id_map, _ = lfm_ds.mapping()\n",
    "    inv_item_map = {v: k for k, v in item_id_map.items()}\n",
    "\n",
    "    for loss in LIGHTFM_LOSSES:\n",
    "        for factors in LIGHTFM_FACTORS:\n",
    "            for epochs in LIGHTFM_EPOCHS:\n",
    "                print(f\"LightFM loss={loss}, factors={factors}, epochs={epochs}\")\n",
    "                model_lfm = LightFM(loss=loss, no_components=factors, random_state=RANDOM_STATE)\n",
    "                model_lfm.fit(interactions, item_features=lfm_item_features, epochs=epochs, num_threads=4)\n",
    "\n",
    "                class LightFMWrapper:\n",
    "                    def recommend(self, user_id: int, known_items: List[int], k: int) -> List[int]:\n",
    "                        if user_id not in user_id_map:\n",
    "                            return []\n",
    "                        uid = user_id_map[user_id]\n",
    "                        scores = model_lfm.predict(uid, np.arange(len(inv_item_map)), item_features=lfm_item_features)\n",
    "                        ranked = np.argsort(-scores)\n",
    "                        recs = []\n",
    "                        known_set = set(known_items)\n",
    "                        for idx in ranked:\n",
    "                            itm = inv_item_map[idx]\n",
    "                            if itm in known_set:\n",
    "                                continue\n",
    "                            recs.append(itm)\n",
    "                            if len(recs) >= k:\n",
    "                                break\n",
    "                        return recs\n",
    "\n",
    "                lfm_wrapper = LightFMWrapper()\n",
    "                metrics_lfm = evaluate_model(lfm_wrapper, ground_truth, users_eval, ks=[5, 10, 20], known_items=known_items_map)\n",
    "                metrics_lfm[\"model\"] = f\"lightfm_{loss}_f{factors}_e{epochs}\"\n",
    "                metrics_lfm[\"svd\"] = SVD_COMPONENTS[0] if USE_SVD else None\n",
    "                all_results_df = pd.concat([all_results_df, metrics_lfm])\n",
    "                all_results_pivot = all_results_df.pivot_table(index=[\"model\", \"svd\"], columns=\"k\", values=[\"hit_rate\", \"recall\", \"ndcg\"])\n",
    "                display(metrics_lfm)\n",
    "except Exception as e:\n",
    "    print(\"LightFM not available or failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78494175",
   "metadata": {},
   "source": [
    "## Logistic regression scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "471957d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogReg samples:   0%|                                                                     | 0/2000 [00:00<?, ?it/s]/tmp/ipykernel_64035/2470827003.py:42: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  content_score = float(item_matrix_lr[idx].dot(profile))\n",
      "/tmp/ipykernel_64035/2470827003.py:53: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  content_score_neg = float(item_matrix_lr[nidx].dot(profile))\n",
      "LogReg samples: 100%|██████████████████████████████████████████████████████████| 2000/2000 [14:03<00:00,  2.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.050116</td>\n",
       "      <td>logreg_neg2_users2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.064907</td>\n",
       "      <td>logreg_neg2_users2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.080908</td>\n",
       "      <td>logreg_neg2_users2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  hit_rate  recall      ndcg                  model\n",
       "0   5    0.0805  0.0805  0.050116  logreg_neg2_users2000\n",
       "1  10    0.1260  0.1260  0.064907  logreg_neg2_users2000\n",
       "2  20    0.1895  0.1895  0.080908  logreg_neg2_users2000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "item_ids_lr, item_to_idx_lr, item_matrix_lr = build_feature_matrix(\n",
    "    base_feats=base_feats,\n",
    "    meta=meta_filtered,\n",
    "    use_svd=USE_SVD,\n",
    "    svd_components=SVD_COMPONENTS[0] if USE_SVD else None,\n",
    ")\n",
    "\n",
    "pop_counts_lr = train_df[ITEM_COL].value_counts()\n",
    "pop_scores_lr = np.zeros(len(item_ids_lr), dtype=np.float32)\n",
    "max_pop_lr = pop_counts_lr.max()\n",
    "for iid, count in pop_counts_lr.items():\n",
    "    idx = item_to_idx_lr.get(iid)\n",
    "    if idx is not None:\n",
    "        pop_scores_lr[idx] = count / max_pop_lr\n",
    "\n",
    "user_profiles = {}\n",
    "for user, grp in train_df.groupby(USER_COL):\n",
    "    idxs = [item_to_idx_lr[i] for i in grp[ITEM_COL] if i in item_to_idx_lr]\n",
    "    if not idxs:\n",
    "        continue\n",
    "    profile = item_matrix_lr[idxs].mean(axis=0)\n",
    "    arr = np.asarray(profile).ravel()\n",
    "    norm = np.linalg.norm(arr)\n",
    "    if norm > 0:\n",
    "        arr = arr / norm\n",
    "    user_profiles[user] = arr\n",
    "\n",
    "X_feat = []\n",
    "y = []\n",
    "users_iter = list(user_profiles.keys())[:LOGREG_MAX_USERS]\n",
    "all_items_arr = np.array(item_ids_lr)\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "\n",
    "for user in tqdm(users_iter, desc=\"LogReg samples\"):\n",
    "    known_list = train_df[train_df[USER_COL] == user][ITEM_COL].tolist()\n",
    "    known_set = set(known_list)\n",
    "    profile = user_profiles[user]\n",
    "    for pos in known_list:\n",
    "        idx = item_to_idx_lr.get(pos)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        content_score = float(item_matrix_lr[idx].dot(profile))\n",
    "        X_feat.append([content_score, pop_scores_lr[idx]])\n",
    "        y.append(1)\n",
    "        neg_candidates = np.setdiff1d(all_items_arr, np.array(list(known_set)), assume_unique=True)\n",
    "        if len(neg_candidates) == 0:\n",
    "            continue\n",
    "        neg_sample = rng.choice(neg_candidates, size=min(LOGREG_NEG_PER_POS, len(neg_candidates)), replace=False)\n",
    "        for neg in neg_sample:\n",
    "            nidx = item_to_idx_lr.get(int(neg))\n",
    "            if nidx is None:\n",
    "                continue\n",
    "            content_score_neg = float(item_matrix_lr[nidx].dot(profile))\n",
    "            X_feat.append([content_score_neg, pop_scores_lr[nidx]])\n",
    "            y.append(0)\n",
    "\n",
    "if X_feat:\n",
    "    X_feat = np.array(X_feat, dtype=np.float32)\n",
    "    y_arr = np.array(y, dtype=np.int8)\n",
    "    clf = LogisticRegression(max_iter=200, n_jobs=4)\n",
    "    clf.fit(X_feat, y_arr)\n",
    "\n",
    "    def logreg_recommend_topk(uid: int, k: int) -> List[int]:\n",
    "        if uid not in user_profiles:\n",
    "            return []\n",
    "        profile = user_profiles[uid]\n",
    "        batch_size = 50000\n",
    "        scores = np.empty(len(item_ids_lr), dtype=np.float32)\n",
    "        for start in range(0, len(item_ids_lr), batch_size):\n",
    "            end = min(start + batch_size, len(item_ids_lr))\n",
    "            sub_idx = np.arange(start, end)\n",
    "            content_scores = np.asarray(item_matrix_lr[sub_idx].dot(profile)).ravel()\n",
    "            pop_sub = pop_scores_lr[sub_idx]\n",
    "            feats = np.stack([content_scores, pop_sub], axis=1)\n",
    "            proba = clf.predict_proba(feats)[:, 1]\n",
    "            scores[sub_idx] = proba\n",
    "        for itm in known_items_map.get(uid, []):\n",
    "            idx = item_to_idx_lr.get(itm)\n",
    "            if idx is not None:\n",
    "                scores[idx] = -np.inf\n",
    "        top_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_idx = top_idx[np.argsort(scores[top_idx])[::-1]]\n",
    "        return [item_ids_lr[i] for i in top_idx]\n",
    "\n",
    "    metrics_lr = evaluate_model(None, ground_truth, users_eval, ks=[5, 10, 20], known_items=known_items_map, recommend_fn=logreg_recommend_topk, exclude_known=False)\n",
    "    metrics_lr[\"model\"] = f\"logreg_neg{LOGREG_NEG_PER_POS}_users{LOGREG_MAX_USERS}\"\n",
    "    all_results_df = pd.concat([all_results_df, metrics_lr])\n",
    "    all_results_pivot = all_results_df.pivot_table(index=[\"model\", \"svd\"], columns=\"k\", values=[\"hit_rate\", \"recall\", \"ndcg\"])\n",
    "    display(metrics_lr)\n",
    "else:\n",
    "    print(\"LogReg skipped: no training samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91a750",
   "metadata": {},
   "source": [
    "## Top models summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36766de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 models by NDCG@10:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>model</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.062581</td>\n",
       "      <td>hybrid_alpha_0.3</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.062347</td>\n",
       "      <td>hybrid_alpha_0.35</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.062211</td>\n",
       "      <td>hybrid_alpha_0.3</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>hybrid_alpha_0.45</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.061942</td>\n",
       "      <td>hybrid_alpha_0.35</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  hit_rate  recall      ndcg              model    svd\n",
       "0  5    0.0885  0.0885  0.062581   hybrid_alpha_0.3  256.0\n",
       "1  5    0.0875  0.0875  0.062347  hybrid_alpha_0.35  256.0\n",
       "2  5    0.0870  0.0870  0.062211   hybrid_alpha_0.3  128.0\n",
       "3  5    0.0870  0.0870  0.062073  hybrid_alpha_0.45  128.0\n",
       "4  5    0.0865  0.0865  0.061942  hybrid_alpha_0.35  128.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 models by NDCG@10:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>model</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.077934</td>\n",
       "      <td>hybrid_alpha_0.45</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.077879</td>\n",
       "      <td>hybrid_alpha_0.4</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.077498</td>\n",
       "      <td>hybrid_alpha_0.35</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.077190</td>\n",
       "      <td>hybrid_alpha_0.45</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.077124</td>\n",
       "      <td>hybrid_alpha_0.4</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  hit_rate  recall      ndcg              model    svd\n",
       "0  10    0.1370  0.1370  0.077934  hybrid_alpha_0.45  256.0\n",
       "1  10    0.1355  0.1355  0.077879   hybrid_alpha_0.4  256.0\n",
       "2  10    0.1345  0.1345  0.077498  hybrid_alpha_0.35  256.0\n",
       "3  10    0.1335  0.1335  0.077190  hybrid_alpha_0.45  128.0\n",
       "4  10    0.1340  0.1340  0.077124   hybrid_alpha_0.4  128.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 models by NDCG@10:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>model</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.091003</td>\n",
       "      <td>hybrid_alpha_0.4</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.090932</td>\n",
       "      <td>hybrid_alpha_0.3</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.090868</td>\n",
       "      <td>hybrid_alpha_0.45</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.090867</td>\n",
       "      <td>hybrid_alpha_0.35</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.090709</td>\n",
       "      <td>hybrid_alpha_0.35</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  hit_rate  recall      ndcg              model    svd\n",
       "0  20    0.1875  0.1875  0.091003   hybrid_alpha_0.4  256.0\n",
       "1  20    0.1890  0.1890  0.090932   hybrid_alpha_0.3  128.0\n",
       "2  20    0.1875  0.1875  0.090868  hybrid_alpha_0.45  128.0\n",
       "3  20    0.1885  0.1885  0.090867  hybrid_alpha_0.35  128.0\n",
       "4  20    0.1870  0.1870  0.090709  hybrid_alpha_0.35  256.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in [5, 10, 20]:\n",
    "    metric = \"ndcg\"\n",
    "    summary = (\n",
    "        all_results_df[all_results_df[\"k\"] == k]\n",
    "        .sort_values(by=metric, ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    print(\"Top 5 models by NDCG@10:\")\n",
    "    display(summary.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f73d6",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Adjust `SAMPLE_USERS` and grids for speed/coverage. For full data, use the HPC script.\n",
    "- BM25 + SVD hybrids are strong; kNN, LightFM, and LogReg provide complementary baselines.\n",
    "- Metrics: HitRate/Recall/NDCG@K (seen items filtered). With one held-out item per user, HitRate and Recall will match.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
