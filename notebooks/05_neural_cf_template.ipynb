{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05 \u2014 Neural CF Template\nStarter PyTorch template for teammate 2. Provides dataset/dataloader, simple MLP model, and evaluation hook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import List\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom src import config\nfrom src.evaluation import build_ground_truth, evaluate_topk\n\nUSER_COL = config.USER_COL\nITEM_COL = config.ITEM_COL\n\nprocessed_dir = config.PROCESSED_DATA_DIR\ntrain_df = pd.read_parquet(processed_dir / \"train_interactions.parquet\")\ntest_df = pd.read_parquet(processed_dir / \"test_interactions.parquet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build integer ID mappings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "users = train_df[USER_COL].unique()\nitems = train_df[ITEM_COL].unique()\nuser_to_idx = {u: i for i, u in enumerate(users)}\nitem_to_idx = {it: i for i, it in enumerate(items)}\nidx_to_item = {i: it for it, i in item_to_idx.items()}\n\ndef encode_df(df: pd.DataFrame) -> pd.DataFrame:\n    return pd.DataFrame({\n        \"user_idx\": df[USER_COL].map(user_to_idx),\n        \"item_idx\": df[ITEM_COL].map(item_to_idx),\n    })\n\ntrain_enc = encode_df(train_df)\ntest_enc = encode_df(test_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset and DataLoader with negative sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class InteractionDataset(Dataset):\n    def __init__(self, interactions: pd.DataFrame, num_items: int, num_neg: int = 4):\n        self.interactions = interactions\n        self.num_items = num_items\n        self.num_neg = num_neg\n        self.positive_pairs = list(zip(interactions[\"user_idx\"], interactions[\"item_idx\"]))\n\n    def __len__(self):\n        return len(self.positive_pairs)\n\n    def __getitem__(self, idx):\n        user, item = self.positive_pairs[idx]\n        users = [user]\n        items = [item]\n        labels = [1.0]\n        rng = np.random.default_rng(idx)\n        for _ in range(self.num_neg):\n            neg_item = rng.integers(0, self.num_items)\n            users.append(user)\n            items.append(neg_item)\n            labels.append(0.0)\n        return torch.tensor(users), torch.tensor(items), torch.tensor(labels, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class NeuralCF(nn.Module):\n    def __init__(self, num_users: int, num_items: int, embedding_dim: int = 64):\n        super().__init__()\n        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n        self.mlp = nn.Sequential(\n            nn.Linear(2 * embedding_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, user_ids, item_ids):\n        u = self.user_embedding(user_ids)\n        i = self.item_embedding(item_ids)\n        x = torch.cat([u, i], dim=-1)\n        return self.mlp(x).squeeze(-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training loop (placeholder)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = NeuralCF(num_users=len(user_to_idx), num_items=len(item_to_idx)).to(device)\noptim = torch.optim.Adam(model.parameters(), lr=1e-3)\nloss_fn = nn.BCELoss()\n\ndataset = InteractionDataset(train_enc, num_items=len(item_to_idx), num_neg=4)\nloader = DataLoader(dataset, batch_size=256, shuffle=True)\n\n# TODO: tune epochs/negatives, add validation, early stopping.\nfor epoch in range(1):\n    for users_batch, items_batch, labels_batch in loader:\n        users_batch = users_batch.view(-1).to(device)\n        items_batch = items_batch.view(-1).to(device)\n        labels_batch = labels_batch.view(-1).to(device)\n\n        preds = model(users_batch, items_batch)\n        loss = loss_fn(preds, labels_batch)\n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n    print(f\"Epoch {epoch} loss {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recommendation wrapper\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def recommend(user_id: int, k: int) -> List[int]:\n    if user_id not in user_to_idx:\n        return list(item_to_idx.keys())[:k]\n    user_idx_val = torch.tensor([user_to_idx[user_id]], device=device)\n    item_indices = torch.arange(len(item_to_idx), device=device)\n    user_vec = user_idx_val.repeat(len(item_indices))\n    with torch.no_grad():\n        scores = model(user_vec, item_indices).cpu().numpy()\n    top_items = scores.argsort()[::-1][:k]\n    return [idx_to_item[i] for i in top_items]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate with shared metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "ground_truth = build_ground_truth(test_df, user_col=USER_COL, item_col=ITEM_COL)\nusers_eval = list(ground_truth.keys())\n\ndef recommend_wrapped(user, k):\n    known = train_df.loc[train_df[USER_COL] == user, ITEM_COL].tolist()\n    recs = recommend(user, k + len(known))\n    return [itm for itm in recs if itm not in known][:k]\n\n# Might be slow; consider subsampling users for quick checks.\nresults = evaluate_topk(ground_truth, recommend_wrapped, users_eval, ks=[5, 10])\nresults\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO: improve negative sampling, add validation split, and move training code into reusable functions if needed.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}